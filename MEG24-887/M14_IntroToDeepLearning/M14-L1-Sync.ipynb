{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging face for pretrained model\n",
    "https://huggingface.co\n",
    "\n",
    "Install instructions for transformer networks\n",
    "https://huggingface.co/docs/transformers/installation\n",
    "\n",
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "meta-llama\n",
    "Llama-3.2-1B \n",
    "\n",
    "https://huggingface.co/meta-llama/Llama-3.2-1B?text=My+name+is+Thomas+and+my+main\n",
    "\n",
    "Model Information\n",
    "\n",
    "The Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out). The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks. They outperform many of the available open source and closed chat models on common industry benchmarks.\n",
    "\n",
    "Model Developer: Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make sure to update your transformers installation via pip install --upgrade transformers.\n",
    "\"\"\"\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model_id, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "pipe(\"The key to life is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pipelines\n",
    "def data():\n",
    "    for i in range(1000):\n",
    "        yield f\"My example {i}\"\n",
    "\n",
    "\n",
    "pipe = pipeline(model=\"openai-community/gpt2\", device=0)\n",
    "generated_characters = 0\n",
    "for out in pipe(data()):\n",
    "    generated_characters += len(out[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing dataset on huggingface\n",
    "https://huggingface.co/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and monitoring: Weights & Biases\n",
    "https://wandb.ai/home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "\n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wandb lets you sweep for model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the W&B Python Library and log into W&B\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "# 1: Define objective/training function\n",
    "def objective(config):\n",
    "    score = config.x**3 + config.y\n",
    "    return score\n",
    "\n",
    "def main():\n",
    "    wandb.init(project=\"my-first-sweep\")\n",
    "    score = objective(wandb.config)\n",
    "    wandb.log({\"score\": score})\n",
    "\n",
    "# 2: Define the search space\n",
    "sweep_configuration = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"score\"},\n",
    "    \"parameters\": {\n",
    "        \"x\": {\"max\": 0.1, \"min\": 0.01},\n",
    "        \"y\": {\"values\": [1, 3, 7]},\n",
    "    },\n",
    "}\n",
    "\n",
    "# 3: Start the sweep\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"my-first-sweep\")\n",
    "\n",
    "wandb.agent(sweep_id, function=main, count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also supports command line interface\n",
    "\n",
    "https://docs.wandb.ai/guides/sweeps/pause-resume-and-cancel-sweeps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config file for a sweep (.yaml)\n",
    "\n",
    "program: run_model_training.py\n",
    "\n",
    "method: bayes\n",
    "\n",
    "metric:\n",
    "\n",
    "  name: val_loss\n",
    "\n",
    "  goal: minimize\n",
    "\n",
    "parameters:\n",
    "\n",
    "  num_GCN_layers:\n",
    "\n",
    "    values: [2,3]\n",
    "\n",
    "  num_GCNneurons:\n",
    "\n",
    "    values: [512,1024]\n",
    "\n",
    "  num_fc_layer:\n",
    "\n",
    "    values: [2,3]\n",
    "\n",
    "  k_pooling_dim:\n",
    "\n",
    "    values: [16, 32]\n",
    "\n",
    "  fc_layer_scaling:\n",
    "\n",
    "    values: [16,32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLI command\n",
    "\n",
    ">> wandb sweep config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, argparse\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "    parser.add_argument('--data', default=\"./data\",\n",
    "                        help = \"Directory with training data\")\n",
    "    parser.add_argument('--train_test_split', default=0.2,\n",
    "                        help = \"ratio of train test split\")\n",
    "    # Architecture and training params\n",
    "    parser.add_argument('--input_feat_dim',default=200, type=int,\n",
    "                        help= \"feature dimension size for input\")\n",
    "    parser.add_argument('--num_GCN_layers',default=2, type=int,\n",
    "                        help='number of GCN layers to use in model (default:4)')\n",
    "    parser.add_argument('--num_GCNneurons',default=256, type=int,\n",
    "                        help='list of number of neurons to use per GCN Layer (default:256)')\n",
    "    parser.add_argument('--k_pooling_dim',default=16, type=int,\n",
    "                        help= \"size of k-pooling layer output dimension\")\n",
    "    parser.add_argument('--num_fc_layer',default=4, type=int,\n",
    "                        help='number of FC to use  to generate predictions (default: 3)')\n",
    "    parser.add_argument('--fc_layer_scaling',default=200, type=int,\n",
    "                        help='Scaling of FC layers wrt graph output dimension (last layer has the output class dimension)')\n",
    "        \n",
    "    parser.add_argument('--num_classes',default=10, type=int,\n",
    "                        help='number of label classes in data')\n",
    "    parser.add_argument('--dropout_rate',default=0.5, type=float)\n",
    "    parser.add_argument('--num-epochs',default=200, type=int)\n",
    "    parser.add_argument('--batch-size',default=2056, type=int)\n",
    "    parser.add_argument('--lr',default=0.001, type=float)\n",
    "    parser.add_argument('--convergence_lr',default=1e-5, type=float)\n",
    "    # Run specific params\n",
    "    parser.add_argument('--model_save_dir',default= \"./model_wt/\")\n",
    "    parser.add_argument('--model_save_th',default= 0.7, type = int,\n",
    "                        help = \"Accuracy threshold for saving a model\")\n",
    "\n",
    "    args = parser.parse_args(sys.argv[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
