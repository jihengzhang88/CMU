{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Autoencoders\n","\n","This week, you learned about autoencoders, which learn to compress data into a low-dimensional _code_ (also called _latent variable_ or _encoding_). You also got familiar with variational autoencoders (VAEs) that enable sample generation. In this session, we are going to implement an autoencoder, and you will implement a variational autoencoder in your assignment. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from typing import Sequence, Union\n","from tqdm import tqdm\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","import ipywidgets as widgets\n","try:\n","    from google.colab import output\n","    output.enable_custom_widget_manager()\n","except ImportError:\n","    pass\n","try:\n","    %matplotlib widget\n","except:\n","    os.system('pip install ipympl -qq')\n","    %matplotlib widget\n","\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","from torch.optim import lr_scheduler\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.datasets import MNIST\n","from torchvision.transforms import v2\n","\n","Device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'Using {Device} device')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"\"\"\n","Load and look at the MNIST dataset\n","\"\"\"\n","\n","train_dataset = MNIST(\n","    root = 'MNIST',\n","    train = True,\n","    download = True,\n","    transform = v2.Compose([\n","        v2.ToImage(),\n","        v2.ToDtype(torch.float32, scale=True),\n","    ]),\n",")\n","\n","test_dataset = MNIST(\n","    root = 'MNIST',\n","    train = False,\n","    download = True,\n","    transform = v2.Compose([\n","        v2.ToImage(),\n","        v2.ToDtype(torch.float32, scale=True),\n","    ]),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ImageDataViz:\n","    \"\"\"\n","    An interactive image data visualzation tool inside Juptyer Notebook.\n","    Make sure to use the magic command: %matplotlib widget\n","    \"\"\"\n","    def __init__(self, dataset: Dataset):\n","        self.dataset = dataset\n","        self.n_samples = len(dataset)\n","        self.index = widgets.IntSlider(\n","            value = 0, \n","            min = 0, \n","            max = self.n_samples-1, \n","            step = 1, \n","            description = 'Index', \n","            continuous_update = True,\n","            layout = widgets.Layout(width='50%'),\n","        )\n","\n","    def update(self, index: int):\n","        x, y = self.dataset[index]\n","        image = x.moveaxis(0, -1).squeeze().numpy()\n","        self.img.set_data(image)\n","        self.ax.set_title(f'Label: {y}')\n","\n","    def show(self):\n","        self.fig, self.ax = plt.subplots()\n","        x, y = self.dataset[0]\n","        image = x.moveaxis(0, -1).squeeze().numpy()\n","        self.img = self.ax.imshow(image, cmap='gray')\n","        self.ax.axis('off')\n","        self.ax.set_title(f'Label: {y}')\n","        widgets.interact(self.update, index=self.index)\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["viz = ImageDataViz(train_dataset)\n","viz.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Defining an autoencoder\n","\n","Typically, an autoencoder reduces the dimension of the data gradually to reach the compact encoding (the encoder's job), and then tries to reconstruct the input from the compact encoding (the decoder's job). Let's take a look at an example:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Encoder(nn.Module):\n","    \n","    def __init__(\n","            self,\n","            input_size: int,\n","            hidden_sizes: Sequence[int],\n","            latent_size: int,\n","            activation: str = 'ReLU',\n","            ):\n","        super().__init__()\n","\n","        act = nn.__getattribute__(activation)\n","\n","        n_layers = len(hidden_sizes) + 1\n","        sizes = hidden_sizes + [latent_size]\n","        self.layers = nn.Sequential(nn.Flatten())\n","\n","        for i in range(n_layers):\n","            in_size = input_size if i == 0 else sizes[i-1]\n","            out_size = sizes[i]\n","            self.layers.append(nn.Linear(in_size, out_size))\n","            if i < n_layers - 1:\n","                self.layers.append(act())\n","\n","    def forward(self, x):\n","        return self.layers(x)\n","    \n","\n","class Decoder(nn.Module):\n","    \n","    def __init__(\n","            self,\n","            latent_size: int,\n","            hidden_sizes: Sequence[int],\n","            output_size: int,\n","            activation: str = 'ReLU',\n","        ):\n","        super().__init__()\n","\n","        act = nn.__getattribute__(activation)\n","\n","        n_layers = len(hidden_sizes) + 1\n","        sizes = hidden_sizes + [output_size]\n","        self.layers = nn.Sequential()\n","\n","        for i in range(n_layers):\n","            in_size = latent_size if i == 0 else sizes[i-1]\n","            out_size = sizes[i]\n","            self.layers.append(nn.Linear(in_size, out_size))\n","            if i < n_layers - 1:\n","                self.layers.append(act())\n","\n","        self.layers.append(nn.Unflatten(1, (1, 28, 28)))\n","        \n","    def forward(self, x):\n","        return self.layers(x)\n","    \n","\n","class Autoencoder(nn.Module):\n","\n","    def __init__(\n","            self,\n","            input_size: int,\n","            hidden_sizes: Sequence[int],\n","            latent_size: int,\n","            activation: str = 'ReLU',\n","        ):\n","        super().__init__()\n","\n","        self.encoder = Encoder(\n","            input_size = input_size, \n","            hidden_sizes = hidden_sizes, \n","            latent_size = latent_size, \n","            activation = activation,\n","            )\n","        \n","        self.decoder = Decoder(\n","            latent_size = latent_size, \n","            hidden_sizes = hidden_sizes[::-1], # reverse order. Gradually increasing the size\n","            output_size = input_size, \n","            activation = activation,\n","            )\n","        \n","    def forward(\n","            self, \n","            x: torch.FloatTensor, # Shape: (batch_size, 1, 28, 28)\n","            ) -> torch.FloatTensor: # Shape: (batch_size, 1, 28, 28)\n","        z = self.encoder(x)\n","        x_hat = self.decoder(z)\n","        return x_hat"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@torch.enable_grad()\n","def train_epoch(\n","    model: nn.Module,\n","    train_loader: DataLoader,\n","    loss_fn: nn.Module,\n","    optimizer: torch.optim.Optimizer,\n","    device: str = Device,\n","    ):\n","\n","    model.train().to(device)\n","\n","    for x, y in train_loader:\n","        x, y = x.to(device), y.to(device)\n","        optimizer.zero_grad()\n","        # Forward pass is not just reconstruction\n","        x_rec = model(x)\n","        # The loss is calculated between the input and the output (input's reconstruction)\n","        loss = loss_fn(x_rec, x)\n","        loss.backward()\n","        optimizer.step()\n","\n","\n","@torch.inference_mode()\n","def eval_epoch(\n","    model: nn.Module,\n","    data_loader: DataLoader, # can be train_loader or val_loader or test_loader\n","    loss_fn: nn.Module,\n","    device: str = Device,\n","    ):\n","    assert loss_fn.reduction in ['mean', 'sum'], 'Invalid reduction method!'\n","\n","    model.eval().to(device)\n","    \n","    n = len(data_loader.dataset)\n","    Loss = 0.\n","\n","    for x, y in data_loader:\n","        b = len(x)\n","        x, y = x.to(device), y.to(device)\n","        # Forward pass is just reconstruction\n","        x_rec = model(x)\n","        # The loss is calculated between the input and the output (input's reconstruction)\n","        loss = loss_fn(x_rec, x)\n","        if loss_fn.reduction == 'mean':\n","            Loss += loss.item()*b\n","        elif loss_fn.reduction == 'sum':\n","            Loss += loss.item()\n","\n","    return Loss/n\n","\n","\n","def train(\n","    # Model and data\n","    model: nn.Module,\n","    train_dataset: Dataset,\n","    test_dataset: Dataset,\n","    loss_fn: nn.Module = nn.MSELoss(reduction='mean'),\n","    device: str = Device,\n","\n","    # train config\n","    optim_name: str = 'Adam', # from optim\n","    optim_config: dict = dict(),\n","    lr_scheduler_name: Union[str, None] = None, # from optim.lr_scheduler\n","    lr_scheduler_config: dict = dict(),\n","    n_epochs: int = 10,\n","    batch_size: int = 32,\n","    ):\n","    \n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    optimizer = optim.__getattribute__(optim_name)(model.parameters(), **optim_config)\n","\n","    if lr_scheduler_name is not None:\n","        scheduler = lr_scheduler.__getattribute__(lr_scheduler_name)(optimizer, **lr_scheduler_config)\n","\n","    epoch_pbar = tqdm(\n","        range(n_epochs),\n","        desc = 'epochs',\n","        unit = 'epoch',\n","        dynamic_ncols = True,\n","        leave = True,\n","        )\n","\n","    for epoch in epoch_pbar:\n","\n","        train_epoch(\n","            model = model,\n","            train_loader = train_loader,\n","            loss_fn = loss_fn,\n","            optimizer = optimizer,\n","            device = device,\n","            )\n","\n","        train_loss = eval_epoch(\n","            model = model,\n","            data_loader = train_loader,\n","            loss_fn = loss_fn,\n","            device = device,\n","            )\n","\n","        test_loss = eval_epoch(\n","            model = model,\n","            data_loader = test_loader,\n","            loss_fn = loss_fn,\n","            device = device,\n","            )\n","\n","        if lr_scheduler_name == 'ReduceLROnPlateau':\n","            scheduler.step(train_loss)\n","        elif lr_scheduler_name is not None:\n","            scheduler.step()\n","\n","        epoch_pbar.set_postfix_str(f'train loss: {train_loss:.4f}, test loss: {test_loss:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_config = dict(\n","    input_size = 28*28,\n","    hidden_sizes = [256, 128, 64, 32],\n","    latent_size = 2,\n","    activation = 'LeakyReLU',\n",")\n","\n","train_config = dict(\n","    optim_name = 'Adam',\n","    optim_config = {},\n","    lr_scheduler_name = 'ReduceLROnPlateau',\n","    lr_scheduler_config = dict(factor=0.5, patience=5),\n","    n_epochs = 5,\n","    batch_size = 64,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    model = Autoencoder(**model_config)\n","    train(\n","        model = model, \n","        train_dataset = train_dataset, \n","        test_dataset = test_dataset, \n","        loss_fn = nn.MSELoss(), \n","        device = Device,\n","        **train_config,\n","        )"]},{"cell_type":"markdown","metadata":{},"source":["# Using a trained autoencoder"]},{"cell_type":"markdown","metadata":{},"source":["## Data compression and reconstruction\n","- We can use the encoder to compress the data. We will lose some quality though. We will compare the data with the reconstruction of the autoencoder.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class AutoEncoderViz:\n","    \"\"\"\n","    Interactive plotting of data and the reconstruction of the autoencoder\n","    \"\"\"\n","    def __init__(\n","            self, \n","            dataset: Dataset, \n","            model: Autoencoder,\n","            ):\n","        self.dataset = dataset\n","        self.n_samples = len(dataset)\n","        self.index = widgets.IntSlider(\n","            value = 0, \n","            min = 0, \n","            max = self.n_samples-1, \n","            step = 1, \n","            description = 'Index', \n","            continuous_update = True,\n","            layout = widgets.Layout(width='50%'),\n","        )\n","\n","        self.model = model.eval().cpu()\n","\n","\n","    def show(self):\n","        self.fig, (self.ax, self.ax2) = plt.subplots(1, 2)\n","        x, y = self.dataset[0]\n","        image = x.moveaxis(0, -1).squeeze().numpy()\n","        self.img = self.ax.imshow(image, cmap='gray', vmin=0, vmax=1)\n","        self.ax.axis('off')\n","        self.ax.set_title(f'Label: {y}')\n","        self.img_rec = self.ax2.imshow(np.zeros((28, 28), dtype=np.float32), cmap='gray', vmin=0, vmax=1)\n","        self.ax2.axis('off')\n","        self.ax2.set_title('Reconstruction')\n","        widgets.interact(self.update, index=self.index)\n","\n","\n","    @torch.inference_mode()\n","    def update(self, index: int):\n","\n","        x, y = self.dataset[index]\n","\n","        image = x.moveaxis(0, -1).squeeze().numpy()\n","        self.img.set_data(image)\n","        self.ax.set_title(f'Label: {y}')\n","\n","        x_rec = self.model(x.unsqueeze(0))[0]\n","        x_rec = x_rec.moveaxis(0, -1).squeeze().numpy()\n","        self.img_rec.set_data(x_rec)\n","\n","        z0, z1 = self.model.encoder(x.unsqueeze(0))[0].numpy()\n","        self.ax2.set_title(f'Latent variable: ({z0:.2f}, {z1:.2f})')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["AEviz = AutoEncoderViz(train_dataset, model)\n","AEviz.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Analyze distribution in latent space\n","\n","We can plot the distribution of the data in the latent space, which is easier to visualize and analyze qualitatively."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@torch.inference_mode()\n","def plot_latent_space():\n","    \"\"\"\n","    Encodes the whole dataset into the latent space\n","    and plots the 2D latent space with different colors for different classes\n","    \"\"\"\n","\n","    model.eval().cpu()\n","\n","    train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n","\n","    train_encoded = []\n","    train_labels = []\n","\n","    for x, y in train_loader:\n","        z = model.encoder(x)\n","        train_encoded.append(z)\n","        train_labels.append(y)\n","\n","    test_encoded = []\n","    test_labels = []\n","\n","    for x, y in test_loader:\n","        z = model.encoder(x)\n","        test_encoded.append(z)\n","        test_labels.append(y)\n","\n","    train_encoded = torch.cat(train_encoded)\n","    train_labels = torch.cat(train_labels)\n","    test_encoded = torch.cat(test_encoded)\n","    test_labels = torch.cat(test_labels)\n","\n","    # 2 subplots for train and test\n","    # different classes are colored differently\n","\n","    fig, axs = plt.subplots(1, 2, figsize=(10, 4), sharex=True, sharey=True)\n","\n","    for i, (encoded, labels) in enumerate([(train_encoded, train_labels), (test_encoded, test_labels)]):\n","        ax = axs[i]\n","        for c in range(10):\n","            idx = labels == c\n","            ax.scatter(encoded[idx, 0].numpy(), encoded[idx, 1].numpy(), label=str(c), alpha=0.5, s=5)\n","        ax.set_title(['Train', 'Test'][i])\n","        ax.grid(linestyle='--')\n","\n","    axs[1].legend(loc=(1.05, 0))\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_latent_space()"]},{"cell_type":"markdown","metadata":{},"source":["## Generation\n","\n","We can use the decoder to generate new samples from arbitrary latent variables. __However__, Not every arbitrary latent variable will lead to a good generated sample."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Generator:\n","    \"\"\"\n","    Generating new samples from arbitrary latent variable using the decoder\n","    \"\"\"\n","    def __init__(\n","            self, \n","            model: Autoencoder,\n","            ):\n","        self.model = model.eval().cpu()\n","\n","\n","    def show(self):\n","\n","        # create widgets fot latent space variables\n","        self.z0 = widgets.FloatSlider(\n","            value = 0.0,\n","            min = -20.0,\n","            max = 20.0,\n","            step = 0.1,\n","            description = 'z0',\n","            continuous_update = True,\n","            layout = widgets.Layout(width='50%'),\n","        )\n","\n","        self.z1 = widgets.FloatSlider(\n","            value = 0.0,\n","            min = -20.0,\n","            max = 20.0,\n","            step = 0.1,\n","            description = 'z1',\n","            continuous_update = True,\n","            layout = widgets.Layout(width='50%'),\n","        )\n","\n","        self.fig, self.ax = plt.subplots()\n","        self.ax.axis('off')\n","        self.img = self.ax.imshow(np.zeros((28, 28), dtype=np.float32), cmap='gray', vmin=0, vmax=1)\n","\n","        widgets.interact(self.update, z0=self.z0, z1=self.z1)\n","\n","\n","    @torch.inference_mode()\n","    def update(self, z0: float, z1: float):\n","\n","        z = torch.tensor([z0, z1], dtype=torch.float32)\n","        x = self.model.decoder(z[None, ...])[0]\n","        image = x.moveaxis(0, -1).squeeze().numpy()\n","        self.img.set_data(image)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["generator = Generator(model)\n","generator.show()"]},{"cell_type":"markdown","metadata":{},"source":["## So what is the point of Variational Autoencoders (VAEs)?\n","\n","In the lectures, you might have heard that VAEs are used for sample generation and have a probabilistic nature. But we just saw that we can also generate samples with a vanilla autoencoder. So what is the point?\n","\n","We cannot always use vanilla (simple) autoencoders because we do not know what is the range and distribution of the data in the learned latent space. Here it was simple because the size of the latent space is small (2) and it is possible to visualize and take a look at what range of latent values correspond to what data samples.\n","\n","In a general situation, the latent space might be relatively high dimensional. For example, high-fidelity image and video data have dimensionality in the order of millions of pixels. In such cases, an encoder can be trained to compress the data into a latent space of size 512. Although the latent space is still much more compressed compared to the original data, the latent space is too high dimensional to be visualized or be assumed to follow within a certain range or distribution that we want it to.\n","\n","This is where variational autoencoders come into play. They have a mechanism to encourage the latent space to follow a certain distribution. You will learn more about VAEs in this week's assignment."]}],"metadata":{"kernelspec":{"display_name":"DL_TA","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":2}